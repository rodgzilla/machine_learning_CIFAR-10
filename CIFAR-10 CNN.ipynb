{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import Activation\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64 # 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test  = to_categorical(y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_pixel_value = X_train.mean().astype(np.float32)\n",
    "std_pixel_value  = X_train.std( ).astype(np.float32)\n",
    "\n",
    "def normalize_input(X):\n",
    "    return (X - mean_pixel_value) / std_pixel_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "augmentation_parameters = {\n",
    "    'width_shift_range'  : 0.1,\n",
    "    'height_shift_range' : 0.1,\n",
    "    'horizontal_flip'    : True\n",
    "}\n",
    "\n",
    "augmented_generator = image.ImageDataGenerator(**augmentation_parameters)\n",
    "batches_generator   = image.ImageDataGenerator()\n",
    "batches             = batches_generator.flow(X_train, y_train, batch_size = batch_size)\n",
    "augmented_batches   = augmented_generator.flow(X_train, y_train, batch_size = batch_size)\n",
    "test_generator      = image.ImageDataGenerator()\n",
    "test_batches        = test_generator.flow(X_test , y_test , batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_deep_cnn(lr = 0.01, nb_epoch = 25):\n",
    "    model = Sequential([\n",
    "            Lambda(normalize_input, input_shape = (3, 32, 32)),\n",
    "            \n",
    "            Convolution2D(32, 3, 3, activation = 'relu', border_mode = 'same'),\n",
    "            Dropout(0.2),\n",
    "            Convolution2D(32, 3, 3, activation = 'relu', border_mode = 'same'),\n",
    "            MaxPooling2D(pool_size = (2, 2)),\n",
    "            \n",
    "            Convolution2D(64, 3, 3, activation = 'relu', border_mode = 'same'),\n",
    "            Dropout(0.2),\n",
    "            Convolution2D(64, 3, 3, activation = 'relu', border_mode = 'same'),\n",
    "            MaxPooling2D(pool_size = (2, 2)),\n",
    "            \n",
    "            Convolution2D(128, 3, 3, activation = 'relu', border_mode = 'same'),\n",
    "            Dropout(0.2),\n",
    "            Convolution2D(128, 3, 3, activation = 'relu', border_mode = 'same'),\n",
    "            MaxPooling2D(pool_size = (2, 2)),\n",
    "            \n",
    "            \n",
    "            Flatten(),\n",
    "            \n",
    "            Dropout(0.2),\n",
    "            Dense(1024, activation = 'relu', W_constraint = maxnorm(3)),\n",
    "            Dropout(0.2),\n",
    "            Dense(512, activation = 'relu', W_constraint = maxnorm(3)),\n",
    "            Dropout(0.2),\n",
    "            \n",
    "            Dense(10, activation = 'softmax')\n",
    "        ])\n",
    "    decay = lr / nb_epoch\n",
    "    sgd = SGD(lr = lr, momentum = 0.9, decay = decay, nesterov = False)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn = get_deep_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fg_parameters = {\n",
    "    'generator'         : batches,\n",
    "    'samples_per_epoch' : batches.N,\n",
    "    'nb_epoch'          : 25,\n",
    "    'validation_data'   : test_batches,\n",
    "    'nb_val_samples'    : test_batches.N\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 30s - loss: 1.7146 - acc: 0.3683 - val_loss: 1.3817 - val_acc: 0.4950\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 30s - loss: 1.2709 - acc: 0.5359 - val_loss: 1.1030 - val_acc: 0.6096\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 30s - loss: 1.0506 - acc: 0.6227 - val_loss: 0.9454 - val_acc: 0.6650\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 30s - loss: 0.9195 - acc: 0.6741 - val_loss: 0.9046 - val_acc: 0.6864\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 30s - loss: 0.8191 - acc: 0.7100 - val_loss: 0.7459 - val_acc: 0.7415\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 29s - loss: 0.7418 - acc: 0.7395 - val_loss: 0.7067 - val_acc: 0.7539\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 29s - loss: 0.6942 - acc: 0.7554 - val_loss: 0.6661 - val_acc: 0.7698\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 29s - loss: 0.6486 - acc: 0.7719 - val_loss: 0.6391 - val_acc: 0.7804\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 30s - loss: 0.6138 - acc: 0.7848 - val_loss: 0.6170 - val_acc: 0.7903\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 30s - loss: 0.5819 - acc: 0.7950 - val_loss: 0.6246 - val_acc: 0.7847\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 30s - loss: 0.5515 - acc: 0.8056 - val_loss: 0.5929 - val_acc: 0.7985\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 30s - loss: 0.5308 - acc: 0.8115 - val_loss: 0.5916 - val_acc: 0.8008\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 29s - loss: 0.5078 - acc: 0.8190 - val_loss: 0.5764 - val_acc: 0.8046\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 31s - loss: 0.4889 - acc: 0.8275 - val_loss: 0.5825 - val_acc: 0.8024\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 29s - loss: 0.4687 - acc: 0.8337 - val_loss: 0.5695 - val_acc: 0.8038\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 30s - loss: 0.4518 - acc: 0.8405 - val_loss: 0.5553 - val_acc: 0.8111\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 30s - loss: 0.4407 - acc: 0.8442 - val_loss: 0.5527 - val_acc: 0.8116\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 29s - loss: 0.4212 - acc: 0.8502 - val_loss: 0.5316 - val_acc: 0.8163\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 30s - loss: 0.4053 - acc: 0.8573 - val_loss: 0.5850 - val_acc: 0.8068\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 29s - loss: 0.3996 - acc: 0.8576 - val_loss: 0.5543 - val_acc: 0.8181\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 29s - loss: 0.3888 - acc: 0.8618 - val_loss: 0.5268 - val_acc: 0.8203\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 29s - loss: 0.3754 - acc: 0.8661 - val_loss: 0.5454 - val_acc: 0.8191\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 30s - loss: 0.3675 - acc: 0.8684 - val_loss: 0.5306 - val_acc: 0.8209\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 30s - loss: 0.3555 - acc: 0.8732 - val_loss: 0.5196 - val_acc: 0.8263\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 29s - loss: 0.3444 - acc: 0.8764 - val_loss: 0.5329 - val_acc: 0.8220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4e20895590>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit_generator(**fg_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_deep_cnn_batchnorm(lr = 0.01, nb_epoch = 25):\n",
    "    model = Sequential([\n",
    "            Lambda(normalize_input, input_shape = (3, 32, 32)),\n",
    "            \n",
    "            Convolution2D(32, 3, 3, activation = 'relu', border_mode = 'same'),\n",
    "            BatchNormalization(axis = 1),\n",
    "            Dropout(0.2),\n",
    "            Convolution2D(32, 3, 3, activation = 'relu', border_mode = 'same'),\n",
    "            BatchNormalization(axis = 1),\n",
    "            MaxPooling2D(pool_size = (2, 2)),\n",
    "            \n",
    "            Convolution2D(64, 3, 3, activation = 'relu', border_mode = 'same'),\n",
    "            BatchNormalization(axis = 1),\n",
    "            Dropout(0.2),\n",
    "            Convolution2D(64, 3, 3, activation = 'relu', border_mode = 'same'),\n",
    "            BatchNormalization(axis = 1),\n",
    "            MaxPooling2D(pool_size = (2, 2)),\n",
    "            \n",
    "            Convolution2D(128, 3, 3, activation = 'relu', border_mode = 'same'),\n",
    "            BatchNormalization(axis = 1),\n",
    "            Dropout(0.2),\n",
    "            Convolution2D(128, 3, 3, activation = 'relu', border_mode = 'same'),\n",
    "            BatchNormalization(axis = 1),\n",
    "            MaxPooling2D(pool_size = (2, 2)),\n",
    "            \n",
    "            \n",
    "            Flatten(),\n",
    "            \n",
    "            Dropout(0.2),\n",
    "            Dense(1024, activation = 'relu', W_constraint = maxnorm(3)),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.2),\n",
    "            Dense(512, activation = 'relu', W_constraint = maxnorm(3)),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.2),\n",
    "            \n",
    "            Dense(10, activation = 'softmax')\n",
    "        ])\n",
    "    decay = lr / nb_epoch\n",
    "    sgd = SGD(lr = lr, momentum = 0.9, decay = decay, nesterov = False)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn_batchnorm = get_deep_cnn_batchnorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fg_parameters = {\n",
    "    'generator'         : batches,\n",
    "    'samples_per_epoch' : batches.N,\n",
    "    'nb_epoch'          : 25,\n",
    "    'validation_data'   : test_batches,\n",
    "    'nb_val_samples'    : test_batches.N\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 74s - loss: 1.6694 - acc: 0.4206 - val_loss: 1.2820 - val_acc: 0.5397\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 72s - loss: 1.1958 - acc: 0.5744 - val_loss: 0.9900 - val_acc: 0.6510\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.9637 - acc: 0.6584 - val_loss: 0.8294 - val_acc: 0.7120\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.8218 - acc: 0.7098 - val_loss: 0.7600 - val_acc: 0.7365\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.7401 - acc: 0.7402 - val_loss: 0.7079 - val_acc: 0.7578\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.6690 - acc: 0.7612 - val_loss: 0.6655 - val_acc: 0.7672\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.6140 - acc: 0.7821 - val_loss: 0.6180 - val_acc: 0.7897\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.5818 - acc: 0.7945 - val_loss: 0.6176 - val_acc: 0.7891\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.5416 - acc: 0.8072 - val_loss: 0.6008 - val_acc: 0.7963\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.5141 - acc: 0.8179 - val_loss: 0.6062 - val_acc: 0.7950\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4816 - acc: 0.8282 - val_loss: 0.5998 - val_acc: 0.7980\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4594 - acc: 0.8377 - val_loss: 0.5717 - val_acc: 0.8124\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4363 - acc: 0.8452 - val_loss: 0.5928 - val_acc: 0.8073\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4155 - acc: 0.8527 - val_loss: 0.5699 - val_acc: 0.8115\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.3990 - acc: 0.8584 - val_loss: 0.5762 - val_acc: 0.8145\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.3781 - acc: 0.8678 - val_loss: 0.5429 - val_acc: 0.8234\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.3684 - acc: 0.8681 - val_loss: 0.5728 - val_acc: 0.8176\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.3544 - acc: 0.8734 - val_loss: 0.5341 - val_acc: 0.8250\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.3413 - acc: 0.8781 - val_loss: 0.5555 - val_acc: 0.8254\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.3257 - acc: 0.8838 - val_loss: 0.5542 - val_acc: 0.8263\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.3166 - acc: 0.8865 - val_loss: 0.5401 - val_acc: 0.8302\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.3057 - acc: 0.8908 - val_loss: 0.5559 - val_acc: 0.8270\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.3074 - acc: 0.8907 - val_loss: 0.5789 - val_acc: 0.8285\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.2935 - acc: 0.8952 - val_loss: 0.5623 - val_acc: 0.8287\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.2827 - acc: 0.8987 - val_loss: 0.5467 - val_acc: 0.8360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4df17288d0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_batchnorm.fit_generator(**fg_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_batchnorm_augmentation = get_deep_cnn_batchnorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fg_parameters = {\n",
    "    'generator'         : augmented_batches,\n",
    "    'samples_per_epoch' : augmented_batches.N,\n",
    "    'nb_epoch'          : 25,\n",
    "    'validation_data'   : test_batches,\n",
    "    'nb_val_samples'    : test_batches.N\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 74s - loss: 1.7279 - acc: 0.3985 - val_loss: 1.3020 - val_acc: 0.5398\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 72s - loss: 1.2696 - acc: 0.5494 - val_loss: 1.0116 - val_acc: 0.6379\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 72s - loss: 1.0679 - acc: 0.6233 - val_loss: 0.9033 - val_acc: 0.6807\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.9471 - acc: 0.6662 - val_loss: 0.7717 - val_acc: 0.7316\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.8562 - acc: 0.6985 - val_loss: 0.7094 - val_acc: 0.7510\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.8012 - acc: 0.7163 - val_loss: 0.6809 - val_acc: 0.7614\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.7590 - acc: 0.7322 - val_loss: 0.6248 - val_acc: 0.7836\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.7236 - acc: 0.7452 - val_loss: 0.6125 - val_acc: 0.7870\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.6897 - acc: 0.7569 - val_loss: 0.5812 - val_acc: 0.7996\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.6771 - acc: 0.7626 - val_loss: 0.5672 - val_acc: 0.8044\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.6524 - acc: 0.7700 - val_loss: 0.5507 - val_acc: 0.8056\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.6308 - acc: 0.7788 - val_loss: 0.5348 - val_acc: 0.8124\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.6112 - acc: 0.7858 - val_loss: 0.5372 - val_acc: 0.8158\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.6008 - acc: 0.7887 - val_loss: 0.5083 - val_acc: 0.8233\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.5874 - acc: 0.7944 - val_loss: 0.4978 - val_acc: 0.8255\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.5688 - acc: 0.7993 - val_loss: 0.4967 - val_acc: 0.8289\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.5635 - acc: 0.8023 - val_loss: 0.4915 - val_acc: 0.8272\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.5563 - acc: 0.8065 - val_loss: 0.4944 - val_acc: 0.8273\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.5474 - acc: 0.8072 - val_loss: 0.4771 - val_acc: 0.8302\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.5325 - acc: 0.8121 - val_loss: 0.4606 - val_acc: 0.8414\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.5279 - acc: 0.8156 - val_loss: 0.4738 - val_acc: 0.8361\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.5239 - acc: 0.8166 - val_loss: 0.4631 - val_acc: 0.8389\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.5175 - acc: 0.8170 - val_loss: 0.4545 - val_acc: 0.8423\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.5060 - acc: 0.8216 - val_loss: 0.4513 - val_acc: 0.8460\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.5036 - acc: 0.8228 - val_loss: 0.4499 - val_acc: 0.8485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4de0972ed0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_batchnorm_augmentation.fit_generator(**fg_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 74s - loss: 0.4982 - acc: 0.8253 - val_loss: 0.4469 - val_acc: 0.8450\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.4917 - acc: 0.8274 - val_loss: 0.4477 - val_acc: 0.8490\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.4852 - acc: 0.8291 - val_loss: 0.4497 - val_acc: 0.8493\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.4831 - acc: 0.8311 - val_loss: 0.4480 - val_acc: 0.8438\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.4743 - acc: 0.8333 - val_loss: 0.4421 - val_acc: 0.8496\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.4697 - acc: 0.8352 - val_loss: 0.4311 - val_acc: 0.8534\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.4689 - acc: 0.8344 - val_loss: 0.4321 - val_acc: 0.8524\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.4692 - acc: 0.8355 - val_loss: 0.4283 - val_acc: 0.8529\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.4603 - acc: 0.8385 - val_loss: 0.4286 - val_acc: 0.8548\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.4559 - acc: 0.8403 - val_loss: 0.4161 - val_acc: 0.8618\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4529 - acc: 0.8400 - val_loss: 0.4198 - val_acc: 0.8535\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4496 - acc: 0.8421 - val_loss: 0.4170 - val_acc: 0.8562\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4452 - acc: 0.8422 - val_loss: 0.4255 - val_acc: 0.8552\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4423 - acc: 0.8423 - val_loss: 0.4195 - val_acc: 0.8557\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4377 - acc: 0.8445 - val_loss: 0.4138 - val_acc: 0.8574\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4392 - acc: 0.8451 - val_loss: 0.4035 - val_acc: 0.8585\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4390 - acc: 0.8463 - val_loss: 0.4165 - val_acc: 0.8540\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4297 - acc: 0.8500 - val_loss: 0.4028 - val_acc: 0.8619\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4316 - acc: 0.8495 - val_loss: 0.4077 - val_acc: 0.8549\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4331 - acc: 0.8479 - val_loss: 0.4056 - val_acc: 0.8587\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 72s - loss: 0.4246 - acc: 0.8501 - val_loss: 0.4028 - val_acc: 0.8633\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4262 - acc: 0.8515 - val_loss: 0.3970 - val_acc: 0.8633\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4194 - acc: 0.8521 - val_loss: 0.4146 - val_acc: 0.8594\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4163 - acc: 0.8539 - val_loss: 0.4065 - val_acc: 0.8630\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 71s - loss: 0.4166 - acc: 0.8542 - val_loss: 0.3859 - val_acc: 0.8644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4deb2f5e10>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_batchnorm_augmentation.fit_generator(**fg_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_batchnorm_augmentation.save_weights('models/cifar10_batchnorm_augmentation.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_batchnorm_augmentation.load_weights('models/cifar10_batchnorm_augmentation.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
